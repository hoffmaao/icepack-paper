\documentclass{article}

\usepackage{amsmath}
%\usepackage{amsfonts}
\usepackage{amsthm}
%\usepackage{amssymb}
%\usepackage{mathrsfs}
%\usepackage{fullpage}
%\usepackage{mathptmx}
%\usepackage[varg]{txfonts}
\usepackage{natbib}
\usepackage{color}
\usepackage[charter]{mathdesign}
\usepackage[pdftex]{graphicx}
%\usepackage{float}
%\usepackage{hyperref}
%\usepackage[modulo, displaymath, mathlines]{lineno}
%\usepackage{setspace}
%\usepackage[titletoc,toc,title]{appendix}

%\linenumbers
%\doublespacing

\theoremstyle{definition}
\newtheorem*{defn}{Definition}
\newtheorem*{exm}{Example}

\theoremstyle{plain}
\newtheorem*{thm}{Theorem}
\newtheorem*{lem}{Lemma}
\newtheorem*{prop}{Proposition}
\newtheorem*{cor}{Corollary}

\newcommand{\argmin}{\text{argmin}}
\newcommand{\ud}{\hspace{2pt}\mathrm{d}}
\newcommand{\bs}{\boldsymbol}
\newcommand{\PP}{\mathsf{P}}

\title{\emph{icepack}: a novel glacier flow modeling package}
\author{Daniel Shapero}
\date{}

\begin{document}

\tableofcontents
\newpage

\maketitle

\begin{abstract}
In this paper we introduce a new software package called \emph{icepack} for modeling the flow of glaciers and ice sheets.
Icepack is built on the finite element modeling library firedrake, which uses the domain-specific language UFL for describing weak forms of partial differential equations.
The diagnostic models in icepack are formulated through action principles that are specified in UFL.
The components of each action functional can be substituted for different forms of the user's choosing, which makes it easy to experiment with the model physics.
Many post-processing and analysis tasks on simulation results also amount to the evaluation of some functional.
By using a variational formulation of the model physics, the specification of a problem and the analysis of the solution employ the same conceptual vocabulary.
A third advantage of variational principles is that the action functional itself can be used to define a solver convergence criterion that is independent of the mesh and requires little tuning on the part of the user.
Icepack features a 3D diagnostic model based on terrain-following coordinates and vertical spectral discretization.
This model resolves both plug- and shear-flow components of horizontal ice flow with a minimum of extra computational expense over 2D, depth-averaged models.
Finally, icepack implements a Gauss-Newton solver for inverse problems that runs substantially faster than the standard BFGS method used in the glaciological literature.
The overall design philosophy of icepack is to be as usable as possible for a wide a swathe of the glaciological community, including both experts and novices in computational science.
\end{abstract}

\section{Introduction}

Numerical modeling has become an essential part of the workflow of glaciologists across all disciplines.
We highlight four main uses of glacier models in the literature:
\begin{enumerate}
    \item predicting future glacier extent and estimating the sea-level rise contribution from glacier dynamics,
    \item exploring aspects of glacier physics, such as hydrology and calving, that are not completely understood,
    \item estimating unobservable quantities, such as bed friction or rheology, from observational data, and
    \item reconstructing what glaciers of the near- or distant-past may have looked like.
\end{enumerate}
Nearly all glaciologists, from graduate students to senior researchers, need to use numerical models at some point in their career.
Several glacier flow models already exist and are effective in the hands of experts.
These models are usually written in compiled programming languages such as C, C++, and Fortran for reasons of computational efficiency.
Many researchers in glaciology, however, receive little or no formal programming training, much less in these languages, and are instead self-taught in either Python or MATLAB.
The ubiquity of C, C++, and Fortran in scientific computing can create a barrier to entry for glaciologists who are not experts in high-performance computing.
Our goal is to make a tool that will be both accessible to non-experts and useful for experts.

The glacier flow modeling package closest in spirit to icepack is VarGlaS \citep{brinkerhoff2013data}.
VarGlaS is implemented using the finite element modeling package FEniCS \citep{logg2012automated}.
The Firedrake project began as an outgrowth of FEniCS and both packages implement the same domain-specific language for describing weak forms of PDE.
Icepack improves upon the groundwork laid in VarGlaS in three main respects.
First, icepack includes a simple 3D flow model that uses several features only available in firedrake: extruded meshes and tensor product finite elements \citep{bercea2016structure, mcrae2016automated}.
This model will be described in section \S\ref{sec:physics-hybrid-model}.
Second, the architecture of icepack is designed to make it easy for users to alter the various physics components, such as the rheology and basal friction, of any of the models included.
The software design that made this possible is discussed in section \S\ref{sec:physics-substitution}.
Finally, the inverse solver in icepack uses the Gauss-Newton method, which converges faster and more reliably than the BFGS method used in VarGlaS; see section \S\ref{sec:numerics-inverse-solvers}.

The two main components of a glacier flow model are a \emph{diagnostic} and a \emph{prognostic} equation.
The diagnostic equation prescribes the ice velocity through a time-independent, nonlinear, elliptic partial differential equation.
The inputs to the diagnostic equation are the ice thickness, surface elevation, velocity at the inflow boundary, rheology, and bed friction coefficient.
The output of the diagnostic equation is the ice velocity throughout the entire domain.
The prognostic equation prescribes how the ice thickness evolves through conservation of mass.
The inputs to the prognostic equation are the current value of the ice thickness, velocity, and the surface and basal mass balance.
The output is the ice thickness at the subsequent timestep.
Mathematically, these two coupled PDEs can be thought of as a differential-algebraic equation.

The rheology and friction coefficient are functions of other fields that have their own evolution equations.
For example, the rheology is a function of temperature, englacial water content, and damage from crevassing.
Likewise, the friction coefficient can be described in terms of the subglacial water pressure and a roughness factor for the underlying bedrock.
The diagnostic and prognostic equations can then be supplemented with evolution equations for these fields, for example the heat equation for temperature, or a hydrology model for subglacial water pressure.


\section{Physics}

\subsection{Mass transport}

The PDE describing how the ice thickness changes in time is a conservative advection equation:
\begin{equation}
    \frac{\partial h}{\partial t} + \nabla\cdot hu = \dot a_s - \dot a_b,
\end{equation}
where $\dot a_s$ and $\dot a_b$ are the surface and basal mass balance.
The thickness is represented using continuous Galerkin basis functions.
The ice thickness and bed elevation are used to update the surface elevation at every timestep, and we need the surface gradient to calculate the driving stress.
The need to calculate gradients of the surface elevation precludes the use of discontinuous Galerkin methods.

The surface elevation is calculated at each timestep of a simulation as
\begin{equation}
    s = \max\{b + h, (1 - \rho_I / \rho_W)h\},
\end{equation}
the first case corresponding to grounded ice and the second case corresponding to floating ice.
In the immediate vicinity of the grounding line, the assumption that the floating ice is in hydrostatic equilibrium with the ocean fails.
Most models assume hydrostasy and icepack does as well.
Elmer/Ice, on the other hand, solves a contact problem for the moving upper and lower ice surfaces and thus can accurately model non-hydrostatic ice shelves \citep{gagliardini2013capabilities}.


\subsection{Momentum transport}

There are \textcolor{green}{three} diagnostic models implemented in icepack.
The \emph{shallow ice approximation} (SIA) and shallow stream approximation (SSA) are 2D models describing the depth-averaged velocity of a glacier.
\textcolor{green}{The SIA model describes the deep interior of ice sheets well, where flow velocities are on the order of 0.1 - 10 m/year.
This model assumes that nearly all flow is by vertical shear, which happens when the ice is frozen to the bed or sliding at a small fraction of the surface speed.}
The SSA model describes the fast-flowing margins of the ice sheet best, encompassing grounded ice streams or floating ice shelves \citep{macayeal1989large}.
This model is appropriate where the sliding velocity is close to the surface velocity, or in other words where the ice is nearly in plug flow.
Plug flow is a good approximation in fast-flowing ice streams and outlet glaciers near the margins of an ice sheet, but deep in the interior the flow is mostly by vertical shear.
The \emph{first-order} or \emph{Blatter-Pattyn} (BP) approximation, by contrast, is a 3D model describing the horizontal velocity \citep{blatter1995velocity, pattyn2003new}.
The only approximation in the BP model is that the flow has a low aspect ratio -- the thickness of the glacier is much less than its horizontal extent.
This approximation may be questionable around, say, the main trunk of Jakobshavn Isbrae in Greenland, which flows through a very deep and narrow trough.
Even Jakobshavn has an aspect ratio on the order of 1/5 and almost all glacier flows have an aspect ratio less than 1/10 or even 1/20.


\subsubsection{Variational principles}

All of the diagnostic models in icepack are described through \emph{variational} or \emph{action} principles \citep{dukowicz2010consistent}.
Rather than describe the velocity as the weak solution of a nonlinear PDE, an action principle instead states that the velocity minimizes a functional called the action.
The action consists of four terms:
\begin{align}
    & \text{action} = \iint\text{stress} \times \text{strain rate}\ud z\ud x - \int\text{basal friction} \times \text{sliding velocity}\ud x \nonumber \\
    & \quad - \iint\text{surface slope}\times\text{velocity}\ud z\ud x - \iint\text{ocean pressure}\times\text{velocity}\ud z\ud \gamma
    \label{action-functional}
\end{align}
where $\ud z\ud x$ denotes integration over the entire glacier, $\ud x$ denotes integration over the glacier footprint, and $\ud z\ud\gamma$ over the side wall boundary.
The action has units of power (energy/time) and can be related to the rate of decrease of the thermodynamic free energy.
Moreover, the energy lost to viscous and frictional heating can be calculated from the action and its Legendre transform.
The action principle can be viewed as a consequence of the Onsager reciprocity relations for systems near to equilibrium \citep{de2013non}.

The action principle is especially useful for designing a robust numerical solver.
For viscous flow problems near to steady-state, the action is \emph{convex} as a function of the ice velocity, i.e. its second derivative is positive-definite.
Convexity implies that the action functional has a unique minimizer and that, with an appropriate line search strategy, Newton's method will converge from any initial guess.
Minimizing a convex action functional is vastly more convenient numerically than solving a general nonlinear equation, although the two formulations are equivalent.


\subsubsection{\textcolor{green}{Shallow ice approximation}}

\subsubsection{Shallow stream approximation}

\subsection{Hybrid model} \label{sec:physics-hybrid-model}

The shallow ice and shallow stream models in icepack are completely standard.
The hybrid flow model that we describe here is based on variational principles, terrain-following coordinates, and vertical spectral methods.
Each of these methods has appeared in the literature on glacier modeling before but never all in the same place for a 3D model.
\citet{langdon1978numerical} and \cite{bassis2010hamilton} used variational principles and vertical spectral methods, but these works considered only flowband and not 3D models.
\citet{kleiner2014numerical} used terrain-following coordinates for 3D glacier flow modeling, but they discretized the problem with finite difference methods in every direction and did not take into account the variational formulation of the diagnostic model.
\citet{jouvet2015multilayer} used vertical semi-discretization of the variational problem, but this model used a finite difference discretization in the vertical direction.

\subsubsection{Terrain-following coordinates}

Rather than use the usual Cartesian coordinate system, the hybrid flow model uses terrain-following coordinates.
The terrain-following vertical coordinate $\zeta$ is
\begin{equation}
    \zeta = \frac{z - b}{h}
\end{equation}
where $b$ is the ice base.
We can then think of the computational domain as the Cartesian product of a 2D footprint domain $\Omega$ and the unit interval $[0, 1]$.

Both the bed elevation and thickness depend on $x$ and $y$.
As a result, the formula for the horizontal gradient of a field in terrain-following coordinates includes an additional geometric correction factor.
Letting $\nabla_z$ and $\nabla_\zeta$ denote the horizontal gradient with respectively $z$ and $\zeta$ held constant, the chain rule gives us that
\begin{equation}
    \nabla_zq = \nabla_\zeta q + \frac{\partial q}{\partial\zeta}\nabla\zeta,
\end{equation}
where we can calculate the spatial gradient of $\zeta$ as
\begin{equation}
    \nabla\zeta = -h^{-1}\left\{(1 - \zeta)\nabla b + \zeta\nabla s\right\}.
\end{equation}
Likewise, the strain rate of a vector field can be expressed as
\begin{equation}
    \dot\varepsilon_z(u) = \dot\varepsilon_\zeta(u) + \frac{1}{2}\left(u \otimes\nabla\zeta + \nabla\zeta\otimes u\right)
    \label{eq:geometric-correction}
\end{equation}
where $\otimes$ is the tensor product of two vectors.

For the Stokes equations, this alternative coordinate system also helps avoid the problem of how to enforce the condition $u\cdot \nu = -\dot a_b$ at the ice base, where $\nu$ is the unit outward normal vector and $\dot a_b$ is the basal mass balance.
This boundary condition is difficult to impose exactly because the unit outward normal vector $\nu$ is defined on mesh faces while the velocity is defined at mesh vertices.
Elmer/Ice uses an ad-hoc procedure to define the unit normal vectors at mesh nodes \citep{gagliardini2013capabilities}.
With a transformation to terrain-following coordinates, we can set the terrain-following vertical velocity $\omega$ to be $-\dot a_b/h$ at the ice base to impose this boundary condition.

We also argue that answers expressed in terrain-following coordinates are more intuitive in some respects than in Cartesian coordinates.
At the bed of a grounded glacier, the vertical velocity in Cartesian coordinates is
\begin{equation}
    w = -\dot a_b + u\cdot\nabla b.
\end{equation}
Knowing that a model gives a vertical velocity at the base of a glacier of, say, 10 cm/year, the modeler needs to also know the bed slope and sliding velocity.
In other words, it is not immediately clear whether the vertical velocity is a result of basal mass balance or of geometry without additional information.
By contrast, the vertical velocity $\omega$ in terrain-following coordinates evaluated at $\zeta = 0$ is completely determined by basal mass balance and ice thickness.


\subsubsection{Spectral discretization}

Terrain-following coordinates open up several choices for how to describe the vertical variation of the velocity field.
In Elmer/Ice, for example, the user can extend the finite element discretization into a number of vertical layers.
The number of vertical layers is a user-tuneable parameter, depending on the desired resolution along this axis \citep{gagliardini2013capabilities}.

The horizontal velocity for many realistic flows is very smooth as a function of depth and this suggests a different approach.
For example, under the plug flow approximation, the horizontal velocity is constant with depth.
Under the shallow ice approximation, the horizontal velocity varies with depth as $1 - (1 - \zeta)^{n + 1}$ where $n = 3$ is the Glen flow law exponent.
This extra information about our solution suggests a modal rather than a nodal discretization strategy.

Rather than divide the spatial domain into many vertical layers, we can instead use only one vertical layer and increase the polynomial degree in the vertical direction to obtain higher resolution.
This type of basis, in which different shape functions are used in different dimensions, is called a \emph{tensor product} element.
Given a set of finite element basis functions $\{\phi_k(x, y)\}$ defined on the 2D domain $\Omega$ and a set of basis functions $\{\psi_l(\zeta)\}$ defined on the unit interval $[0, 1]$, the tensor product finite element basis $\{\Phi_{kl}\}$ on the extruded domain is defined as
\begin{equation}
    \Phi_{kl}(x, y, \zeta) = \phi_k(x, y)\psi_l(\zeta).
\end{equation}
For example, we can use piecewise linear or quadratic elements on triangles and use quintic or higher degree polynomials in the vertical.
Rather than use the usual Lagrange interpolating polynomial basis in the vertical dimension, we can instead use the Legendre polynomial basis.
The Legendre polynomials are mutually orthogonal and this choice makes the mass matrix block-diagonal.

The combination of using extruded meshes and tensor product elements in the vertical direction is referred to as \emph{semi-discretization}.
This approach can be thought of merely as a way to discretize a PDE that has special structure.
Alternatively, we can view vertical semi-discretization as defining a family of models indexed by the number of vertical basis functions.
The order-$d$ model defines a coupled system of PDEs for $d$ vector fields.
Each vector field represents one mode of vertical variability, similar to the distinction between barotropic and baroclinic modes in atmospheric physics and oceanography.
The system is then discretized in the horizontal and solved numerically.
In any case, the code is the same regardless of how one views the underlying mathematics.

The user then has to decide how many vertical modes are enough.
Using only degree 0 is exactly equivalent to the shallow stream approximation and we use this fact as a ``smoke test'' for the hybrid model.
The degree 1 model is the most minimalistic model that still exhibits vertical shear.
Going to higher degree gives a more accurate approximation at the expense of greater computational effort.

\subsection{Substituting model components} \label{sec:physics-substitution}

Many aspects of glacier physics are not completely understood.
For example, the most common description of basal friction assumes that glacier sliding occurs through regelation, in which case the basal shear stress can be written
\begin{equation}
    \tau_b = -C|u|^{\frac{1}{m} - 1}u
\end{equation}
with $m = 3$ \citep{weertman1957sliding}.
Many authors have argued that, in fast-flowing regions of the ice sheet, glacier sliding occurs instead by plastic deformation within the subglacial sediments \citep{tulaczyk2000basal}.
For plastic sliding, the shear stress is dependent on the yield strength of the subglacial sediments and not on the sliding speed, in which case $m = \infty$ would be most appropriate.
Finally, the Schoof sliding law aims to reconcile the two modes of sliding \citep{schoof2005effect}.
Below a critical sliding speed, the shear stress is aymptotic to $|u|^{1/m}$ as in the Weertman sliding law, but above the critical speed the shear stress is independent of the sliding speed.

The Weertman and plastic sliding laws possess the same functional form but differ only in the value of a single scalar parameter $m$.
The Schoof sliding law, on the other hand, has a totally different functional dependence on the velocity.
Several authors, including Schoof, have proposed that the basal shear stress is also a function of the effective pressure $N = \rho gh - p_w$ within the subglacial hydrological system \citep{budd1979empirical, schoof2005effect}.
Implementing these more sophisticated mathematical models would require adding an extra argument to the procedure for solving the diagnostic equation.

One of our goals with icepack is to facilitate experimentation with the model physics.
To support use cases like implementing the Schoof sliding law, it must be possible to completely alter the functional form of a given model physics component.
For uses cases like explicitly adding the dependence of basal shear stress on hydrology, it must also be possible to add entirely new fields to a given model physics component.
In programming terms, this amounts to changing the number of arguments to the function that calculates basal shear stress.
For a library developed in C or Fortran, the user would then also have to change the signature of the diagnostic solve function.
In C++ one could avoid modifying the diagnostic solve routine by using variadic templates.
Variadic templates are a more advanced language feature and relying on them would present a steep learning curve for novices.

Any model physics component in icepack can be substituted for a parameterization of the user's choosing.
Each flow model object is initialized with a set of functions to calculate the various terms of the action functional.
For example, the ice stream model is initialized with functions to calculate the contributions due to viscosity, basal friction, side wall drag, and gravity.
The default parameterizations are set to the most common choices in the literature, but if the user does wish to change a given component, they can pass a function that they write to the initializer for the model object.
When the diagnostic solve procedure is invoked, all of its arguments are then passed on by keyword to the method that calculates the action functional.
Any fields that are unnecessary for calculating a given component are ignored.
For example, the rheology and friction coefficient are passed to the function that calculates the gravitational driving power, and this function makes no use of these arguments.
The user can completely change the functional form and add new arguments, with the restriction that arguments are passed by keyword and not positionally.

In adopting this approach, we are restricted to using keyword arguments instead of positional arguments.
Using only keyword arguments enhances readability and comprehensibility for this particular case of invoking a physics solver.
The user only needs to know the argument names, which are chosen to agree with what symbols are commonly used in the literature -- $C$ for friction, $A$ for rheology, $N$ for effective pressure, etc.
The order of the arguments is arbitrary and immaterial.
The preference for argument passing by name is specific to this use case and not universal.
For example, in defining a bilinear form that represents a non-symmetric PDE, the order of the arguments has intrinsic mathematical significance.
In that case using positional arguments would better correspond with the underlying problem.

One of our main design goals for icepack is to enable users to ``plug and play'' their own physics.
Since many aspects of glacier flow are not understood completely, we view extensibility as an essential requirement for any software package in this domain.
Writing the entire package in Python was necessary to meet this goal.
Many scientific software packages consist of a highly-optimized core library in C, C++, or Fortran, together with a wrapper that exposes this library to an interpreted language like Python.
This approach in principle offers the best of both worlds -- the runtime efficiency of a compiled language with the convenience and interactivity of an interpreted one.
Many practitioners, however, will use such a library entirely through the interpreted surface layer and have no familiarity with the language in which the fast core was written.
These users then have a steep learning curve to overcome when they need to modify functionality that lives in the core library, as they now need to learn an entirely new programming language.
Some low-level kernel code is, of course, always necessary for runtime efficiency.
With Firedrake, this responsibility is deferred to a code generator.
The average user can remain largely unaware of how the code generator works even when solving very advanced problems.


\subsection{Data assimilation}

Icepack includes a set of routines for estimating the basal friction or rheology coefficients from observational data.
The class \texttt{InverseProblem} represents the specification of the inverse problem.
To specify an inverse problem, the user must provide:
\begin{itemize}
    \item the model object and the method that solves the diagnostic equation,
    \item the objective and regularization functionals,
    \item the observed field and the name of the argument to the diagnostic solver,
    \item an initial guess for the field to be estimated and the name of the argument to the diagnostic solver,
    \item extra data passed to the diagnostic solver such as boundary conditions.
\end{itemize}
At present, this class assumes that the observed state is always the ice velocity, but in principle the same design would suffice for more complicated inverse problems.
More importantly, the inverse problem is flexible enough to account for the fact that we might have substituted in our own parameterization for the rheology or friction coefficient.
For example, nearly all studies in the literature use an alternate parameterization of the friction coefficient in terms of some auxiliary field in order to guarantee positivity \citep{macayeal1992basal, joughin2009basal}.
This information is passed to the inverse problem by specifying the names of the keyword arguments for the observed state and the field we wish to observe.

The \texttt{InverseSolver} class is responsible for actually solving the inverse problem.
This class will be described further in section \S\ref{sec:numerics-inverse-solvers}.
The inverse solver is completely agnostic to the particular parameterization of the physics in terms of the inferred field as long as it guarantees positivity.
This feature interacts seamlessly with the ability to modify individual model physics components as described in \S\ref{sec:physics-substitution}.


\subsection{Damage transport}

\subsection{Heat transport}

\subsection{\textcolor{green}{Plumes}}



\section{Numerics}

In this section we describe how various parts of the model physics were implemented in icepack, including both software design and the numerical solution procedures.
From a design perspective, each flow model is represented by a Python class that has three responsibilities.
First, the model class has to have a method that takes in the various fields (ice velocity, thickness, surface elevation, etc.) and returns a symbolic representation of the action functional for that particular model.
Second, the model class must have a method that takes in the input fields and returns an approximate minimizer of the action functional.
The diagnostic solve method amounts to invoking an external Newton solve procedure on the symbolic action functional that the first method calculates.
The Newton solver itself is completely standard but the convergence criterion is not and will be discussed in section \S\ref{sec:convergence-criteria}.
Finally the model must have a method to update the ice thickness from the current value, the ice velocity, and the mass balance rates.
The prognostic solver will be discussed in section \S\ref{sec:prognostic-model}.

The Unified Form Language for specifying weak forms of PDEs contains all of the primitives necessary to express individual terms of the action functional.
These primitives consist of the basic vector calculus operators like the gradient of a field, tensor calculus operations like taking the dot product of two vectors or tensors, scalar functions like the square root or exponential, and symbolic integration over the mesh or its boundary.
For example, the strain rate for a given velocity field $u$ can be written as \texttt{sym(grad(u))}, where the function \texttt{grad} represents the symbolic gradient of a field and \texttt{sym} represents the symmetrization of a rank-2 tensor.


\subsection{Advective transport} \label{sec:prognostic-model}

The simplest explicit timestepping schemes are unstable with continuous Galerkin finite elements.
To solve the mass transport equation, other packages use the streamlined upwind Petrov-Galerkin (SUPG) method for the timestepping scheme \citep{brinkerhoff2013data, larour2012continental}.
The SUPG method with an explicit time discretization is conditionally stable \citep{donea2003finite}.
This scheme introduces a tuneable stabilization parameter, so in the interest of simplicity we instead default to the implicit Euler scheme.
The implicit Euler scheme requires solving a non-symmetric linear system, but the computational cost comes with the advantage of unconditional stability.

Practicing glaciologists who have not studied numerical PDE may be unfamiliar with the Courant-Friedrichs-Lewy condition.
The use of an unconditionally stable scheme guarantees that they will get an answer should they try to use a large timestep rather than a runtime error.
The extra cost of using an implicit time discretization for the mass transport equation is dwarfed by the cost of the diagnostic solve in any case.
Advanced users who are interested in maximizing performance can subclass the mass transport solver to implement a faster explicit scheme.

The implicit Euler scheme tends to diffuse out sharp discontinuities that may be present in the true solution \citep{donea2003finite}.
Since the ice thickness does not possess shockwaves or propagating discontinuities this error mode is tolerable.
The coupling of ice thickness to velocity makes the whole system more resemble a parabolic problem than a hyperbolic one, and under the shallow ice approximation the system is truly parabolic.
Other problems within glaciology have more of a hyperbolic character and there the argument for using shock-capturing methods is much stronger.
For example, in continuum damage mechanics, the thresholding behavior of the source terms can induce sharp discontinuities in the damage field \citep{albrecht2014fracture}.
The implicit Euler scheme would obscure this feature and an alternative method such as the strong stability-preserving Runge Kutta method would be more appropriate.


\subsection{Convex optimization}

The action functional for each diagnostic model is convex, i.e. the second derivative is positive-definite.
\textcolor{red}{Why it's great...}

Other software packages that treat diagnostic models as nonlinear systems of equations tend to rely on ad-hoc procedures for initializing the numerical solution process.
For example, without a damping procedure in Newton's method, the iteration can prove unstable if initialized far away from the true solution.
Some packages combat this problem by using a few iterations of the more robust but slower Picard method first \citep{gagliardini2013capabilities}.
While this approach can be effective it requires tuning the number of Picard iterations and there is no guarantee that an adequate amount for one problem will work well on another problem.
This issue rarely appears on realistic input data.
When solving inverse problems, however, the intermediate guesses for the inferred field can be wildly unrealistic before converging.
A forward model solver that is not sufficiently robust can crash in these extreme scenarios.
By contrast, a damped Newton procedure using a line search that satisfies the Armijo-Wolfe criteria is guaranteed to converge on non-degenerate, if unrealistic, input data.


\subsection{Convergence metrics} \label{sec:convergence-criteria}

Calculating the ice velocity from the geometry and other input fields involves minimizing a convex functional.
The minimizer can only be approximated, so we employ iterative procedures based on Newton's method with a line search.
We must then choose some metric to decide when the current guess for the velocity is good enough to stop the iteration.

A convergence criterion that works equally well independent of the mesh, finite element discretization, and the quality of the initial guess can be defined based on the idea of the \emph{Newton decrement} \citep{nocedal2006numerical}.
The search direction $v_k$ at step $k$ for Newton's method is defined as
\begin{equation}
    v_k = -\ud^2J(u_k)^{-1}\ud J(u_k).
\end{equation}
Since the second derivative operator $\ud^2J(u_k)$ is positive-definite, this is a descent direction for the action $J$:
\begin{equation}
    \ud J(u_k)\cdot v_k < 0.
\end{equation}
The absolute value of the quantity in the last equation is defined as the Newton decrement.
For $u_k$ sufficiently close to the true solution $u$, the Newton decrement roughly tells us how much we can expect the action to decrease:
\begin{equation}
    J(u_k) - J(u) \approx \frac{1}{2}|\ud J(u_k)\cdot v_k|.
\end{equation}
We can then use the Newton decrement to decide when to stop the iteration.

As shown in equation \eqref{action-functional}, the action has units of power and is the sum of the dissipation due to viscosity, friction, gravitational driving, and ocean back-pressure at the terminus.
The viscous and frictional terms are convex, positive functions of the velocity.
The gravitational and terminus stress terms are linear in the velocity and can be of either sign.
If we define the \emph{scale functional}
\begin{equation}
    K(u) = \text{viscous dissipation} + \text{frictional dissipation}
\end{equation}
as only the positive parts of the action, then the convergence criterion
\begin{equation}
    |\ud J(u_k)\cdot v_k| < \epsilon K(u_k)
\end{equation}
is independent of the discretization.
The intuition behind this criterion is that the iteration is halted when the expected decrease in the action functional is much smaller than the positive part of the action itself.

We have found empirically that, with this criterion and the Newton solver implementation in icepack, the iteration usually converges to machine precision in around 8 steps.
The iteration count can reach as high as 20 for exceptionally bad initial guesses for the velocity or with unphysical fluidity or friction values.
We also observe the expected doubling of the number of accurate digits in the value of the action once the velocity guesses are within the convergence basin of the true solution.
Other convergence criteria, such as using relative change in the velocity guesses, can terminate prematurely when the initial guess is very far outside the quadratic convergence basin.

The numerical solvers in icepack have been designed so that users who are not familiar with numerical optimization need not be confronted with a possibly bewildering array of algorithmic parameters.
Consequently, sensible defaults have been chosen for the Armijo and Wolfe criteria \citep{nocedal2006numerical}, and the tolerance for the line search is chosen based on that of the outer-level Newton iteration.
The Newton search direction is calculated using a direct factorization solver rather than, say, the conjugate gradient algorithm, as the use of another iterative method would introduce yet another algorithmic parameter.
Advanced users who are interested in performance optimization can change these algorithmic parameters by passing extra arguments to the solve procedure.


\subsection{Inverse solvers} \label{sec:numerics-inverse-solvers}

The \texttt{InverseProblem} class describes what problem is being solved, while the \texttt{InverseSolver} class is responsible for carrying out the numerical optimization.
There are three inverse solvers in icepack: a simple gradient descent solver, a quasi-Newton solver based on the BFGS approximation to the Hessian, and a Gauss-Newton solver.
All of these classes are based around the general idea of first computing a search direction and then performing a line search.
They differ in how the search direction is computed.

The gradient descent solver uses the search direction
\begin{equation}
    \phi_k = -M^{-1}\ud J(\theta_k)
\end{equation}
where $M$ is the finite element mass matrix.
Gradient descent is a popular choice because the objective functional is always decreasing along this search direction.
However, the search direction can be poorly scaled to the physical dimensions of the problem at hand.
This method can be very expensive and brittle in the initial iterations and often takes many steps to converge.

The BFGS method uses the past $m$ iterations of the algorithm to compute a low-rank approximation to the inverse of the objective functional's Hessian matrix; see \citet{nocedal2006numerical} for a more in-depth discussion.
The BFGS method converges faster than gradient descent.
However, it suffers from many of the same brittleness issues in the initial iterations before it has built up enough history to approximate the Hessian inverse.

Finally, the Gauss-Newton solver defines an approximation to the ``first-order'' part of the objective functional Hessian.
Each iteration of Gauss-Newton is more expensive than that of BFGS or gradient descent because it requires the solution of a more complex linear system than just the mass matrix.
The Gauss-Newton method converges fastest by far in virtually every test case we have found, in some instances by up to factor of 50.

The derivative of the objective functional with respect to the unknown parameter is calculated using the symbolic differentiation features of Firedrake.
The user does not need to provide any routines for the derivatives, only the symbolic form of the error metric and the regularization functional.
The model object is responsible for providing the symbolic form of the action functional.


\subsection{Hybrid model}

The hybrid flow uses several features that are only available in firedrake to better exploit the special structure of the problem.
Implementing this model also required some mathematical sleight-of-hand related to the terminus boundary condition that has not appeared in the literature before.
Additionally, the hierarchical structure of spectral basis functions presents an opportunity for developing fast algorithms.
In all other respects the implementation of the hybrid flow model using convex optimization follows the techniques described above.

\subsubsection{Discretization}

In order to use terrain-following coordinates, the hybrid model assumes that the geometry of the domain is an extruded mesh, where a 2D footprint mesh is lifted into 3D.
Firedrake includes support for creating extruded meshes by calling the function \texttt{ExtrudedMesh} on the 2D footprint \citep{bercea2016structure}.
The cells of an extruded mesh are triangular prisms instead of the more common tetrahedra used for general 3D meshes.
Not every 3D domain can be described by extruding a 2D domain, but the geometry of most glacier flow problems can.

The geometric correction factor in equation \eqref{eq:geometric-correction} for gradients in terrain-following coordinates can easily be represented in UFL.
By defining a wrapper around the UFL \texttt{grad} function, the code to define the action functional in terrain-following coordinates is only slightly more complex than in Cartesian coordinates.

For problems defined on extruded geometries, firedrake includes support for tensor product elements, which includes using different bases in the horizontal and vertical directions \citep{mcrae2016automated}.
Tensor product elements are defined in Firedrake by passing the extra keyword arguments \texttt{vfamily}, \texttt{vdegree} to the constructor for a function space.
In our case, we used the usual continuous Galerkin basis in the horizontal and Gauss-Legendre elements in the vertical.
To select the Legendre polynomial basis, the user passes the keyword argument \texttt{vfamily=`Gauss-Legendre'} or \texttt{`GL'} for short to the constructor for the function space.

Extruded meshes and tensor product elements are available in firedrake but not in FEniCS.
Other general-purpose finite element modeling packages that support tensor product elements include deal.II and nektar++ \citep{bangerth2007deal, cantwell2015nektar++}.
Like most other packages in this domain, deal.II and nektar++ are written in C++, whereas our goal for icepack was to have both the core and the user interface in Python.

\subsubsection{Ocean boundary condition}

Our approach for implementing a hybrid flow model works completely seamlessly but for one important detail.
The backpressure from ocean water at the calving front of a marine-terminating glacier is not a smooth function of depth.
The pressure is 0 above the water line and linearly increasing below it:
\begin{equation}
    \text{backpressure power} = \int_\Gamma\int_0^1 \rho_Wgh(\zeta_{\text{sl}} - \zeta)_+\ud\zeta\ud\gamma,
    \label{backpressure}
\end{equation}
where $\zeta_{\text{sl}}$ denotes the relative depth to the water line and the subscript $+$ denotes the positive part of a real number.
Were we to use the standard asssembly procedure in Firedrake to evaluate this integral, we would get an inaccurate result due to an insufficient number of integration points.
The resulting velocity solutions are then wildly inaccurate due to the mis-specification of the Neumann boundary condition.
A blunt solution to this problem would be to pass an extra argument to the Firedrake form compiler that specifies a much greater integration accuracy in the vertical for this term.
This fix reduces the errors in the velocities, but it does not eliminate them completely and it incurs a large computational cost.

\begin{figure}[h]
    \includegraphics[width=0.95\linewidth]{demos/legendre/pressure.png}
    \caption{The normalized ocean pressure ($p_w / \rho_Wg$) and Legendre polynomial approximations of several degrees (left), and the residuals of the approximation (right).
    For this particular example, the waterline is at $\zeta = 1/3$.
    The moments of each of the residuals up to the approximation degree are all zero.}
    \label{fig:legendre}
\end{figure}

We instead implemented a routine that symbolically calculates the Legendre polynomial expansion of the function $(\zeta_{\text{sl}} - \zeta)_+$ with respect to the parameter $\zeta_{\text{sl}}$ using the package SymPy \citep{sympy}.
The symbolic variables for $\zeta$ and $\zeta_{\text{sl}}$ used in the SymPy representation of the polynomial expansion are then substituted for equivalent symbolic variables in Firedrake/UFL using the SymPy object's \texttt{subs} method.
The Legendre polynomial approximation to this function only converges linearly as the number of coefficients is increased, since the the function is continuous but not smooth, and the approximation exhibits noticeable ringing artifacts at high degree.
While the approximation itself is not very accurate, the calculated value of the integral in equation \eqref{backpressure} is exact because of the orthogonality property of Legendre polynomials.
Stated another way, the residuals in the approximation are large, but they integrate to 0 when multiplied by any Legendre polynomial up to the number of vertical modes.
An example of the pressure approximations using linear, quadratic, and cubic Legendre polynomials are shown in figure \ref{fig:legendre}.

The exact symbolic integration approach is both faster and more accurate than using a large number of quadrature points.
The same technique could be used to exactly calculate the ocean backpressure for any model, say the full Stokes equations, using terrain-following coordinates together with a Legendre polynomial expansion in the vertical.


\subsubsection{Multigrid-type algorithm}

One of the main advantages of this hybrid model is the ease with which a more accurate solution can be bootstrapped from a less accurate solution, since the two fields are defined on exactly the same geometry.
For example, if we only have a very crude initial guess for the solution, we can obtain a degree-1 solution relatively cheaply.
The resulting velocity field is then used as a much more informed initial guess for a degree-5 solution.
\textcolor{red}{Benchmark.}
Since the vertical basis functions are orthogonal, the projection of the degree-1 solution into the degree-5 function space can be calculated by simply copying array elements.
By contrast, if we tried to use the same strategy to bootstrap a solution with a small number of vertical layers to a solution with a larger number of vertical layers, we would also have to interpolate values to the fine layers.

Other hybrid models in the literature use only a fixed number of vertical basis functions.
For example, \citet{bassis2010hamilton} use only the two vertical basis functions $\psi_1(\zeta) = 1$, $\psi_2(\zeta) = 1 - (1 - \zeta)^{n + 1}$, the idea being that the vertical profile can be written as a direct superposition of the plug flow and shallow ice approximation modes.
By contrast, we leave the number of vertical basis functions up to the user.
This flexibility enables the multigrid-type approach described above.

The bootstrapping approach described here can be used both for the forward model and for inverse problems.
First, we estimate the unknown parameter using only degree-1 vertical basis functions for the velocity field, which captures most of the spatial variability of the unknown parameter.
The resulting coefficient is then used as the initial guess with higher degree vertical basis functions for the velocity \textcolor{red}{benchmark}.



\section{Demonstrations}

\subsection{ISMIP-HOM}

\subsection{Larsen C Ice Shelf}

\subsection{Jakobshavn Isbrae}



\section{Usability}

One of the main goals for icepack is to create a tool that is accessible to researchers who might not be experts in scientific computing.
Previous work on numerical modeling of glacier flow has focused largely on technical details of the models themselves -- does a given solver converge with the accuracy expected from finite element theory, does it scale to large numbers of processors, can models accurately predict grounding line retreat, etc.
The fallible human learning to use the model is largely absent from the discussion.

The field of \emph{human-computer interaction} (HCI) asks how we can design software that is easiest to learn and use effectively.
In the following, we will describe some of the design choices in icepack and how they relate to what HCI researchers call the \emph{cognitive dimensions of notations}.
\citet{green1996usability} introduced this concept to assess the usability of visual programming languages, but the criteria they laid out in this paper have been used to analyze software systems across many disciplines.

\textbf{Consistency: After a user learns part of the software, can they guess the remaining parts?}
Each of the model objects in icepack is a class with a method ending in \texttt{solve} that takes in keyword arguments for the various input fields and options for things like boundary conditions.
Users already familiar with, say, the \texttt{IceStream} class can then use the \texttt{HeatTransport} class under the assumption that the input fields -- the current temperature $T$, ice velocity $u$, and basal melt rate $m$ -- are passed as keyword arguments with the same name as the fields themselves.
This obviates the need for consulting the documentation or examples.

\textbf{Progressive evaluation: How easily can users get feedback during their use of the software?}
Progressive evaluation is the main advantage of having a user interface in Python or another interpreted language, as opposed to using compiled programs that must run all at once.
Icepack includes a suite of example programs that demonstrate all of the main functions of the package.
These demos are formatted as Jupyter notebooks, a document format that includes code, figures, and explanatory text with typeset mathematics that runs interactively in a web browser \citep{kluyver2016jupyter}.
A notebook is a sequence of cells, each of which consists of either code or text.
The code cells can be executed one-at-a-time and this enables users to insert diagnostics in each cell as they go.
Most importantly, the notebook format also integrates the plotting library matplotlib so that figures created in each cell appear directly beneath that cell as it is executed.
The ability to visualize the current state of the simulation at every step is a powerful tool for debugging and sanity-checking.
\textcolor{red}{Picture of an executed jupyter notebook.}
Finally, a Jupyter notebook and the accompanying plots can be rendered into HTML and published using the tool \texttt{nbconvert}.

\textbf{Abstraction gradient: What are the levels of abstraction exposed by the library?
Can irrelevant details be hidden?}
The API for icepack has been designed so that the user only needs to make decisions about what problem they wish to solve and not how to solve it.
Where a choice concerns more the ``how'' than the ``what'', a sensible default has been chosen.
Moreover, the default behavior we choose always biases for correctness rather than speed.
For example, the Newton solver uses a direct factorization method to solve the linear system for the search direction because factorization requires no tuning whereas iterative methods do.
A user interested in achieving greater runtime performance can pass additional keyword arguments instead specifying, say, the conjugate gradient method.
This choice is of interest mostly to advanced users so we keep the linear solver method as a default argument.
In so doing, we avoid confronting novice users with options that they might not understand.

Advanced users who wish to tune solver performance for large simulations will need some way to make choices about algorithms.
For example, a more advanced user might choose the GMRES iterative solver together with an incomplete LU preconditioner to solve linear systems.
The solver classes, as opposed to the model classes, provide the interface for making these kinds of algorithmic choices.
While alternative solvers might offer faster runtime performance than direct factorization, they also requires making additional choices choices -- how often to restart GMRES?
How much fill-in to allow in the incomplete factorization?
Many glaciologists do not have the background in numerical linear algebra to know that adjusting these parameters could make the difference between solver convergence or breakdown.
Similarly, users might want to select between different discretization strategies for the Stokes equations, which must be chosen carefully in order to satisfy the Ladyzhenskaya-Babu\v{s}ka-Brezzi (LBB) conditions \citep{boffi2013mixed}.
When using Galerkin least-squares \textcolor{red}{check that's actually what it is} stabilization of the weak form, the user has to pick a value of the stabilization parameter.
Determining exactly what value of this parameter is necessary to guarantee stability is a subtle problem, even more so for the kinds of highly anisotropic meshes that are commonly encountered in 3D glacier flow modeling.
If the solver fails to converge, it might not be obvious even to an expert whether the problem lies with the stabilization or the aforementioned parameters of the linear solver.


\section{Discussion}



\bibliographystyle{plainnat}
\bibliography{icepack.bib}

\end{document}
